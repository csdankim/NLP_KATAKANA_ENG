# Natural Language Processing
## Project: Cipher / Decipher Katakana and English
## 0. n-gram Language Models and Entropy
&nbsp;

## A. [Instruction and Problems](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/ex2.pdf)
## B. [Report](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/ex2_report.pdf)
## C. Codes
- [make_uni.py](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/make_uni.py)
- [make_bi.py](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/make_bi.py)
- [make_tri.py](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/make_tri.py)
- [make_bi_smooth.py](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/make_bi_smooth.py)
- [make_tri_smooth.py](https://github.com/csdankim/NLP_KATAKANA_ENG/blob/master/0.%20n-gram%20language%20model/make_tri_smooth.py)
