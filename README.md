# Natural Language Processing
## Project: Cipher / Decipher Katakana and English
&nbsp;

## Goal
Following [Kevin Knight](https://kevincrawfordknight.github.io/)'s tradition, understand and implement followings:
- finite-state machines (weighted FSAs and FSTs)
- syntactic structures (weighted context-free grammars and parsing algorithms)
- machine learning methods (maximum likelihood and expectation-maximization)
- modern quantitative techniques in NLP that use large corpora and statistical learning
- various dynamic programming algorithms (Viterbi, CKY, Forward-Backward, and Inside-Outside)
-  Japanese language as a running example to demonstrate the linguistic diversity, to illustrate transliteration and translation, and to understand the Viterbi and EM algorithms
- For the linguistic background of Japanese, please see this [video](https://www.youtube.com/watch?v=x9-e_3GHrzw&feature=youtu.be).
- For finite-state toolkit, USC ISI's [CARMEL](https://github.com/isi-nlp/carmel) is used. 

&nbsp;
## Contents
### [0. n-gram Language Models and Entropy](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/0.%20n-gram%20language%20model)
### [1. FSAs & FSTs recovering spaces and vowels](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/1.%20FSAs_FSTs_recovering%20spaces%20and%20vowels)
### [2. English pronunciation, part-of-speech tagging as composition, Katakana-to-English (back)transliteration](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/2.%20English%20pronunciation%2C%20part-of-speech%20tagging%20as%20composition%2C%20Katakana-to-English%20(back)transliteration)
### [3. Viterbi decoding for POS tagging and Katakana-to-English (back)transliteration](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/3.%20Viterbi%20decoding%20for%20POS%20tagging%20and%20Katakana-to-English%20(back)transliteration)
### [4. EM to learn Katanana-English correspondence; EM for decipherment](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/4.%20EM%20to%20learn%20Katanana-English%20correspondence%3B%20EM%20for%20decipherment)
### [5. Syntax, CFG, and CKY parsing](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/5.%20Syntax%2C%20CFG%2C%20and%20CKY%20parsing)
### [6. Recurrent Neural Language Models and Beam Search](https://github.com/csdankim/NLP_KATAKANA_ENG/tree/master/6.%20Recurrent%20Neural%20Language%20Models_Beam%20Search)